import logging, os, sys, subprocess, json, traceback, re, datetime, shutil, uuid, queue, threading, time
from flask import Flask, request, Response, render_template, jsonify
import webbrowser
from threading import Timer

# --- ä¸»åº”ç”¨ä»£ç  ---
try:
    from flask_cors import CORS
except ImportError:
    CORS = None

# å®šä¹‰ä¸€ä¸ªå…¨å±€çš„ã€åªåœ¨Windowsä¸Šç”Ÿæ•ˆçš„åˆ›å»ºæ ‡å¿—ï¼Œç”¨äºéšè—å­è¿›ç¨‹çª—å£
CREATE_NO_WINDOW = subprocess.CREATE_NO_WINDOW if sys.platform == 'win32' else 0

def resource_path(relative_path):
    try:
        base_path = sys._MEIPASS
    except Exception:
        base_path = os.path.abspath(".")
    return os.path.join(base_path, relative_path)

# --- åŸºæœ¬é…ç½®å’Œæ—¥å¿— ---
COOKIES_FILE = resource_path("cookies.txt")
YTDLP_PATH = resource_path("yt-dlp.exe")
ARIA2C_PATH = resource_path(os.path.join("aria2", "aria2-1.36.0-win-64bit-build1", "aria2c.exe"))
FFMPEG_BUNDLED_PATH = resource_path(os.path.join("ffmpeg", "bin", "ffmpeg.exe"))
FFMPEG_SYSTEM_PATH = "ffmpeg.exe"
DOWNLOAD_DIR = os.path.join(os.path.expanduser('~'), 'Desktop')
os.makedirs(DOWNLOAD_DIR, exist_ok=True)

# --- ä»»åŠ¡é˜Ÿåˆ—å’ŒçŠ¶æ€ç®¡ï¿½ï¿½ ---
download_queue = queue.Queue()
tasks = {}
tasks_lock = threading.Lock()

# --- ç¼“å­˜ ---
_ffmpeg_path_cache = None
video_info_cache = {}

def get_ffmpeg_path():
    global _ffmpeg_path_cache
    if _ffmpeg_path_cache is not None: return _ffmpeg_path_cache
    if os.path.exists(FFMPEG_BUNDLED_PATH):
        try:
            subprocess.run([FFMPEG_BUNDLED_PATH, '-version'], capture_output=True, check=True, creationflags=CREATE_NO_WINDOW, timeout=5)
            logger.info("ä½¿ç”¨æ‰“åŒ…çš„ FFmpeg")
            _ffmpeg_path_cache = FFMPEG_BUNDLED_PATH
            return _ffmpeg_path_cache
        except: logger.warning("æ‰“åŒ…çš„ FFmpeg ä¸å¯ç”¨")
    try:
        subprocess.run([FFMPEG_SYSTEM_PATH, '-version'], capture_output=True, check=True, creationflags=CREATE_NO_WINDOW, timeout=5)
        logger.info("ä½¿ç”¨ç³»ç»Ÿ FFmpeg")
        _ffmpeg_path_cache = FFMPEG_SYSTEM_PATH
        return _ffmpeg_path_cache
    except: logger.warning("ç³»ç»Ÿ FFmpeg ä¸å¯ç”¨")
    _ffmpeg_path_cache = False
    return None

LANGUAGE_CODES = {'en': 'è‹±è¯­', 'zh-CN': 'ç®€ä½“ä¸­æ–‡', 'zh-Hant': 'ç¹ä½“ä¸­æ–‡', 'ja': 'æ—¥è¯­', 'ko': 'éŸ©è¯­', 'de': 'å¾·è¯­', 'fr': 'æ³•è¯­', 'es': 'è¥¿ç­ç‰™è¯­', 'ru': 'ä¿„è¯­'}

def setup_logging():
    log_dir = os.path.join(DOWNLOAD_DIR, "æµå…‰ä¸‹è½½å™¨æ—¥å¿—")
    os.makedirs(log_dir, exist_ok=True)
    log_format = '%(asctime)s - %(levelname)s - %(message)s'
    root_logger = logging.getLogger()
    if root_logger.hasHandlers(): root_logger.handlers.clear()
    console_handler = logging.StreamHandler(sys.stdout)
    console_handler.setLevel(logging.INFO)
    console_handler.setFormatter(logging.Formatter(log_format))
    file_handler = logging.FileHandler(os.path.join(log_dir, f'app_{datetime.datetime.now().strftime("%Y%m%d")}.log'), encoding='utf-8')
    file_handler.setLevel(logging.DEBUG)
    file_handler.setFormatter(logging.Formatter(log_format))
    root_logger.setLevel(logging.DEBUG)
    root_logger.addHandler(console_handler)
    root_logger.addHandler(file_handler)
    return logging.getLogger(__name__)

logger = setup_logging()
app = Flask(__name__, template_folder=resource_path('templates'), static_folder=resource_path('static'))
if CORS: CORS(app)

def get_video_info(url, is_playlist=False):
    """è·å–è§†é¢‘ä¿¡æ¯ï¼Œæ·»åŠ è¶…æ—¶å’Œç¼“å­˜æœºåˆ¶ã€‚ä¸ºæ’­æ”¾åˆ—è¡¨å•ç‹¬å¤„ç†ã€‚"""
    # å¯¹æ’­æ”¾åˆ—è¡¨ç¦ç”¨ç¼“å­˜ï¼Œå› ä¸ºå†…å®¹å¯èƒ½ç»å¸¸å˜åŒ–
    if not is_playlist:
        cache_key = url
        if cache_key in video_info_cache:
            logger.info("ä½¿ç”¨ç¼“å­˜çš„è§†é¢‘ä¿¡æ¯")
            return video_info_cache[cache_key]

    # åŸºç¡€å‘½ä»¤
    cmd = [YTDLP_PATH, '--no-warnings', '--dump-json', '--no-check-certificate',
           '--socket-timeout', '15', '--extractor-retries', '3']

    # ä¸ºæ’­æ”¾åˆ—è¡¨ä½¿ç”¨ --flat-playlist æé«˜æ•ˆç‡
    if is_playlist:
        cmd.extend(['--flat-playlist'])
    else:
        # å•ä¸ªè§†é¢‘ä¸å¤„ç†æ’­æ”¾åˆ—è¡¨ï¼ŒåŠ å¿«é€Ÿåº¦
        cmd.extend(['--no-playlist'])

    cmd.append(url)

    # æ·»åŠ  Cookies
    if os.path.exists(COOKIES_FILE):
        cmd.extend(['--cookies', COOKIES_FILE])
    else:
        try:
            cmd.extend(['--cookies-from-browser', 'chrome'])
        except Exception:
            logger.warning("æ— æ³•ä»æµè§ˆå™¨è‡ªåŠ¨æå– cookies")

    try:
        process = subprocess.run(cmd, capture_output=True, text=True, encoding='utf-8',
                               errors='ignore', creationflags=CREATE_NO_WINDOW, timeout=30)

        if process.returncode != 0:
            raise Exception(f"è·å–è§†é¢‘ä¿¡æ¯å¤±è´¥: {process.stderr}")

        lines = process.stdout.strip().split('\n')
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯æ’­æ”¾åˆ—è¡¨çš„å“åº”
        first_line_data = json.loads(lines[0])
        is_playlist_response = first_line_data.get('_type') == 'playlist' or 'playlist' in first_line_data

        if is_playlist_response:
            # å¦‚æœæ˜¯æ’­æ”¾åˆ—è¡¨ï¼Œæˆ‘ä»¬å·²ç»ç”¨äº† --flat-playlistï¼Œç›´æ¥å¤„ç†
            info = [json.loads(line) for line in lines]
            playlist_title = info[0].get('playlist_title') or info[0].get('title', 'æœªçŸ¥æ’­æ”¾åˆ—è¡¨')
            for entry in info:
                entry['is_playlist'] = True
                entry['playlist_title'] = playlist_title
            return info
        else:
            # å•ä¸ªè§†é¢‘
            info = json.loads(lines[0])
            if not is_playlist:
                if len(video_info_cache) >= 20:
                    video_info_cache.pop(next(iter(video_info_cache)))
                video_info_cache[url] = info
            return info

    except subprocess.TimeoutExpired:
        raise Exception("è·å–è§†é¢‘ä¿¡æ¯è¶…æ—¶")
    except json.JSONDecodeError:
        raise Exception("è§†é¢‘ä¿¡æ¯è§£æå¤±è´¥")

def download_worker():
    """åå°ä¸‹è½½å·¥ä½œçº¿ç¨‹ï¼Œç°åœ¨èƒ½å¤„ç†è§†é¢‘å’Œå­—å¹•"""
    while True:
        task_id = download_queue.get()
        if task_id is None: break

        with tasks_lock:
            tasks[task_id]['status'] = 'downloading'
            task = tasks[task_id]
        
        try:
            if task['type'] == 'video':
                execute_video_download(task_id, task)
            elif task['type'] == 'subtitle':
                execute_subtitle_download(task_id, task)
            else:
                raise ValueError(f"æœªçŸ¥çš„ä»»åŠ¡ç±»å‹: {task['type']}")

        except Exception as e:
            logger.error(f"ä»»åŠ¡ {task_id} å¤±è´¥: {traceback.format_exc()}")
            with tasks_lock:
                if task_id in tasks:
                    tasks[task_id]['status'] = 'error'
                    tasks[task_id]['error_message'] = str(e)
        
        download_queue.task_done()

def execute_video_download(task_id, task):
    """æ‰§è¡Œè§†é¢‘ä¸‹è½½"""
    url = task['url']
    if not url: raise ValueError("ä»»åŠ¡URLä¸ºç©º")

    title = re.sub(r'[\/*?:"><>|]', '_', task.get('title', 'video_file'))
    output_path = os.path.join(DOWNLOAD_DIR, f"{title[:150]}.mp4")
    
    format_string = 'bestvideo[height<=1080]+bestaudio[ext=m4a]/best' if task['quality'] == 'best' else 'best[height<=720]/best'
    
    dl_cmd = [YTDLP_PATH, '--no-warnings', '--force-overwrites', '--no-check-certificate', 
             '--socket-timeout', '12', '--retries', '3', '--fragment-retries', '5',
             '--no-part', '--concurrent-fragments', '4', '--no-playlist',
             '-f', format_string, '--merge-output-format', 'mp4', '-o', output_path]

    if os.path.exists(COOKIES_FILE): dl_cmd.extend(['--cookies', COOKIES_FILE])
    else: dl_cmd.extend(['--cookies-from-browser', 'chrome'])
    
    ffmpeg_path = get_ffmpeg_path()
    if ffmpeg_path: dl_cmd.extend(['--ffmpeg-location', ffmpeg_path])
    if os.path.exists(ARIA2C_PATH):
        dl_cmd.extend(['--downloader', 'aria2c', '--downloader-args', "max-connection-per-server=16,min-split-size=1M"])
    
    dl_cmd.append(url)
    
    process = subprocess.Popen(dl_cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, 
                             text=True, encoding='utf-8', errors='ignore', bufsize=1, 
                             creationflags=CREATE_NO_WINDOW)

    for line in iter(process.stdout.readline, ''):
        percent = -1
        match_aria = re.search(r'\((\d{1,3})%\)', line)
        if match_aria: percent = int(match_aria.group(1))
        else:
            match_ydl = re.search(r'\[download\]\s+([\d\.]+)\s*%', line)
            if match_ydl: percent = float(match_ydl.group(1))
        
        with tasks_lock:
            if task_id in tasks:
                if percent >= 0: tasks[task_id]['progress'] = percent
                if '[Merger]' in line: tasks[task_id]['status'] = 'merging'

    process.wait()
    if process.returncode == 0 and os.path.exists(output_path):
        with tasks_lock:
            if task_id in tasks:
                tasks[task_id]['status'] = 'finished'
                tasks[task_id]['progress'] = 100
    else:
        error_output = process.stderr.read() if process.stderr else "æœªçŸ¥é”™è¯¯"
        raise RuntimeError(f"ä¸‹è½½å¤±è´¥: {error_output}")

def execute_subtitle_download(task_id, task):
    """æ‰§è¡Œå­—å¹•ä¸‹è½½å’Œå¤„ç†"""
    url = task['url']
    lang = task['sub_lang']
    if not url or not lang: raise ValueError("URLæˆ–å­—å¹•è¯­è¨€ä¸ºç©º")

    title = re.sub(r'[\/*?:"><>|]', '_', task.get('title', 'video_file').replace('[å­—å¹•] ', ''))
    output_base = os.path.join(DOWNLOAD_DIR, f"{title[:150]}")
    
    with tasks_lock:
        tasks[task_id]['progress'] = 20

    subtitle_extensions = ('.srt', '.vtt', '.ass')
    files_before = {f for f in os.listdir(DOWNLOAD_DIR) if f.endswith(subtitle_extensions)}

    dl_cmd = [YTDLP_PATH, '--no-warnings', '--force-overwrites', '--no-check-certificate',
             '--write-subs', '--sub-langs', lang, '--skip-download',
             '--convert-subs', 'srt', '-o', output_base]
    
    if os.path.exists(COOKIES_FILE): dl_cmd.extend(['--cookies', COOKIES_FILE])
    else: dl_cmd.extend(['--cookies-from-browser', 'chrome'])

    ffmpeg_path = get_ffmpeg_path()
    if ffmpeg_path: dl_cmd.extend(['--ffmpeg-location', ffmpeg_path])

    dl_cmd.append(url)
    
    process = subprocess.run(dl_cmd, capture_output=True, text=True, encoding='utf-8', errors='ignore', creationflags=CREATE_NO_WINDOW)
    
    if process.returncode != 0:
        raise RuntimeError(f"yt-dlpä¸‹è½½å­—å¹•å¤±è´¥: {process.stderr}")

    with tasks_lock:
        tasks[task_id]['progress'] = 70
        tasks[task_id]['status'] = 'merging' # ç”¨mergingè¡¨ç¤ºæ­£åœ¨åå¤„ç†

    files_after = {f for f in os.listdir(DOWNLOAD_DIR) if f.endswith(subtitle_extensions)}
    new_files = files_after - files_before
    
    if not new_files:
        raise RuntimeError("æ‰¾ä¸åˆ°ä¸‹è½½çš„å­—å¹•æ–‡ä»¶ï¼Œè¯·æ£€æŸ¥yt-dlpçš„è¾“å‡º")

    # ä¼˜å…ˆé€‰æ‹©SRT
    srt_files = [f for f in new_files if f.endswith('.srt')]
    subtitle_file_name = srt_files[0] if srt_files else new_files.pop()
    subtitle_file_path = os.path.join(DOWNLOAD_DIR, subtitle_file_name)

    # --- æ¢å¤çš„æ ¸å¿ƒï¼šSRTæ–‡ä»¶å¤„ç† ---
    try:
        with open(subtitle_file_path, 'r', encoding='utf-8') as f:
            content = f.read()

        blocks = content.strip().split('\n\n')
        cleaned_blocks = []
        for block in blocks:
            lines = block.strip().split('\n')
            if len(lines) >= 2:
                index_line = lines[0]
                time_line = lines[1]
                text_lines = [line.strip() for line in lines[2:] if line.strip()]
                
                if text_lines:
                    merged_text = ' '.join(text_lines)
                    cleaned_block = f"{index_line}\n{time_line}\n{merged_text}"
                    cleaned_blocks.append(cleaned_block)
        
        final_content = '\n\n'.join(cleaned_blocks)
        with open(subtitle_file_path, 'w', encoding='utf-8') as f:
            f.write(final_content)
        logger.info(f"å­—å¹•æ–‡ä»¶ {subtitle_file_name} å·²æˆåŠŸå¤„ç†ã€‚")
    except Exception as e:
        logger.error(f"å¤„ç†SRTæ–‡ä»¶æ—¶å‡ºé”™: {e}")
        raise RuntimeError("å­—å¹•æ–‡ä»¶åå¤„ç†å¤±è´¥")

    with tasks_lock:
        if task_id in tasks:
            tasks[task_id]['status'] = 'finished'
            tasks[task_id]['progress'] = 100


@app.route('/')
def index():
    return render_template('index.html')

@app.route('/info')
def video_info_route():
    url = request.args.get('url')
    if not url: return jsonify({'error': 'ç¼ºå°‘URLå‚æ•°'}), 400
    
    try:
        # ç»ˆæä¿®å¤ V2ï¼šé€»è¾‘æ›´æ¸…æ™°
        # 1. ä¼˜å…ˆåˆ¤æ–­æ˜¯å¦ä¸ºæ’­æ”¾åˆ—è¡¨
        is_playlist = 'list=' in url
        
        # 2. å¦‚æœæ˜¯æ’­æ”¾åˆ—è¡¨ï¼Œå¼ºåˆ¶ä½¿ç”¨ --flat-playlist
        if is_playlist:
            info = get_video_info(url, is_playlist=True)
            
            if not isinstance(info, list): # yt-dlp å¯èƒ½åªè¿”å›ä¸€ä¸ª playlist ï¿½ï¿½ï¿½å‹çš„ json
                info = info.get('entries', [])

            playlist_title = "æœªçŸ¥æ’­æ”¾åˆ—è¡¨"
            # å°è¯•ä»ç¬¬ä¸€ä¸ªæœ‰æ•ˆçš„è§†é¢‘æ¡ç›®ä¸­è·å–åˆ—è¡¨æ ‡é¢˜
            if info and info[0] and info[0].get('playlist_title'):
                playlist_title = info[0].get('playlist_title')
            
            videos = [{'id': entry.get('id'), 'url': entry.get('webpage_url', entry.get('url')), 'title': entry.get('title', 'æœªçŸ¥æ ‡é¢˜')} for entry in info if entry]
            return jsonify({'type': 'playlist', 'title': playlist_title, 'videos': videos, 'playlist_url': url})

        # 3. å¦‚æœä¸æ˜¯æ’­æ”¾åˆ—è¡¨ï¼Œåˆ™ä½œä¸ºå•ä¸ªè§†é¢‘å¤„ç†
        else:
            info = get_video_info(url, is_playlist=False)
            if isinstance(info, list): info = info[0] # é˜²å¾¡æ€§ç¼–ç¨‹

            title = info.get('title', 'æœªçŸ¥æ ‡é¢˜')
            sub_options = []
            found_langs = set()
            
            manual_subs = info.get('subtitles', {})
            auto_captions = info.get('automatic_captions', {})
            
            for lang_code in sorted(manual_subs.keys()):
                if lang_code not in found_langs:
                    display_name = LANGUAGE_CODES.get(lang_code, lang_code)
                    sub_options.append({'value': lang_code, 'text': f'{display_name} (å®˜æ–¹)'})
                    found_langs.add(lang_code)

            for lang_code in sorted(auto_captions.keys()):
                simple_lang_code = lang_code.split('-')[0]
                if simple_lang_code not in found_langs:
                    display_name = LANGUAGE_CODES.get(simple_lang_code, simple_lang_code)
                    sub_options.append({'value': lang_code, 'text': f'{display_name} (è‡ªåŠ¨)'})
                    found_langs.add(simple_lang_code)
            
            return jsonify({
                'type': 'video', 
                'title': title, 
                'id': info.get('id'), 
                'url': info.get('webpage_url', url),
                'sub_options': sub_options
            })
            
    except Exception as e:
        logger.error(f"è·å–ä¿¡æ¯å¤±è´¥: {traceback.format_exc()}")
        return jsonify({'error': str(e)}), 500

@app.route('/add_to_queue', methods=['POST'])
def add_to_queue():
    data = request.json
    videos = data.get('videos', [])
    quality = data.get('quality', 'best')
    task_type = data.get('task_type', 'video') # 'video' or 'subtitle'
    sub_lang = data.get('sub_lang')

    if not videos:
        return jsonify({'error': 'æ²¡æœ‰è¦æ·»åŠ çš„é¡¹ç›®'}), 400

    added_count = 0
    with tasks_lock:
        for video in videos:
            if not video or not video.get('url'):
                logger.warning(f"è·³è¿‡æ— æ•ˆä»»åŠ¡ï¼ˆç¼ºå°‘URLï¼‰ï¼š{video.get('title', 'æœªçŸ¥æ ‡é¢˜')}")
                continue

            task_id = str(uuid.uuid4())
            
            title = video['title']
            if task_type == 'subtitle':
                title = f"[å­—å¹•] {title}"

            tasks[task_id] = {
                'id': task_id,
                'url': video['url'],
                'title': title,
                'status': 'queued',
                'progress': 0,
                'type': task_type,
                # ç‰¹å®šäºç±»å‹çš„æ•°æ®
                'quality': quality if task_type == 'video' else None,
                'sub_lang': sub_lang if task_type == 'subtitle' else None,
            }
            download_queue.put(task_id)
            logger.info(f"ä»»åŠ¡ {task_id} ({title}) å·²æ·»åŠ åˆ°é˜Ÿåˆ—")
            added_count += 1

    if added_count > 0:
        return jsonify({'message': f'{added_count} ä¸ªä»»åŠ¡å·²æ·»åŠ åˆ°é˜Ÿåˆ—'})
    else:
        return jsonify({'error': 'æœªèƒ½æ·»åŠ ä»»ä½•æœ‰æ•ˆä»»åŠ¡'}), 400

@app.route('/queue_status')
def queue_status():
    with tasks_lock:
        tasks_copy = list(tasks.values())
    
    status_order = {'downloading': 0, 'merging': 1, 'queued': 2, 'finished': 3, 'error': 4}
    sorted_tasks = sorted(tasks_copy, key=lambda x: status_order.get(x['status'], 99))
    
    return jsonify(sorted_tasks)

@app.route('/clear_finished', methods=['POST'])
def clear_finished():
    with tasks_lock:
        finished_task_ids = [task_id for task_id, task in tasks.items() if task['status'] in ['finished', 'error']]
        for task_id in finished_task_ids:
            del tasks[task_id]
    logger.info(f"æ¸…é™¤äº† {len(finished_task_ids)} ä¸ªå·²å®Œæˆ/é”™è¯¯çš„ä»»åŠ¡")
    return jsonify({'message': 'å·²æ¸…é™¤å·²å®Œæˆçš„ä»»åŠ¡'})


def open_browser():
    webbrowser.open_new("http://127.0.0.1:5001")

if __name__ == '__main__':
    logger.info("ğŸš€ æ­£åœ¨åˆå§‹åŒ–æµå…‰ä¸‹è½½å™¨...")
    get_ffmpeg_path()
    
    worker_thread = threading.Thread(target=download_worker, daemon=True)
    worker_thread.start()
    logger.info("âœ… åå°ä¸‹è½½çº¿ç¨‹å·²å¯åŠ¨")

    if not os.path.exists(COOKIES_FILE):
        logger.warning("="*50)
        logger.warning("æœªæ‰¾åˆ° cookies.txt æ–‡ä»¶ï¼è¯·æ³¨æ„éœ€è¦ç™»å½•çš„ç½‘ç«™å¯èƒ½ä¸‹è½½å¤±è´¥ã€‚")
        logger.warning("="*50)
    
    logger.info("æœåŠ¡å™¨å³å°†å¯åŠ¨åœ¨ http://127.0.0.1:5001")
    Timer(1, open_browser).start()
    
    app.config['SEND_FILE_MAX_AGE_DEFAULT'] = 0
    app.config['TEMPLATES_AUTO_RELOAD'] = True
    app.config['JSON_AS_ASCII'] = False
    
    @app.after_request
    def after_request(response):
        response.headers['Cache-Control'] = 'no-cache, no-store, must-revalidate'
        response.headers['Pragma'] = 'no-cache'
        response.headers['Expires'] = '0'
        return response
    
    logger.info("ğŸ¬ æµå…‰ä¸‹è½½å™¨å¯åŠ¨æˆåŠŸï¼")
    app.run(host='127.0.0.1', port=5001, debug=False, use_reloader=False, threaded=True)
